#!/bin/bash
### sbatch config parameters must start with #SBATCH and must precede any other command. to ignore just add another # - like so ##SBATCH
#SBATCH --partition main                         ### specify partition name where to run a job. short - 7 days time limit; debug â€“ for testing - 2 hours and 1 job at a time
#SBATCH --time 3-11:30:00                      ### limit the time of job running. Make sure it is not greater than the partition time limit!! Format: D-H:MM:SS
#SBATCH --job-name data_chunks                   ### name of the job. replace my_job with your desired job name

#SBATCH --mail-user=reutme@post.bgu.ac.il      ### users email for sending job status notifications
#SBATCH --mail-type=END,FAIL            ### conditions when to send the email. ALL,BEGIN,END,FAIL, REQUEU, NONE

#SBATCH --ntasks=1
#SBATCH --cpus-per-task=6

#SBATCH --output merge_chunks_%A_%a.out           ### output log for running job - %J is the job number variable

### Print some data to output file ###
echo "SLURM_JOBID"=$SLURM_JOBID
echo "SLURM_JOB_NODELIST"=$SLURM_JOB_NODELIST

### Start you code below ####
module load anaconda              ### load anaconda module
source activate muscle_diff       ### activating Conda environment, environment must be configured before running the job


arg_modality=$1
feature_calc=$2

python /home/reutme/muscle-formation-regeneration/TimeSeriesAnalysis/params_tunning/run_merge_preprocess_data_chunks.py $arg_modality $feature_calc


