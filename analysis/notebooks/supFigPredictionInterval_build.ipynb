{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63ddc7da-0dd6-45f3-85a6-74b949df3922",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tsfresh import select_features\n",
    "import datetime\n",
    "from tsfresh import defaults\n",
    "from tsfresh.feature_selection.relevance import calculate_relevance_table\n",
    "from tsfresh.utilities.dataframe_functions import check_for_nans_in_columns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_curve\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "import joblib\n",
    "import re\n",
    "from collections import Counter\n",
    "import sys, os\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11777e30-316c-4883-bf84-681a643a6de8",
   "metadata": {},
   "source": [
    "### configuration ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "847d09c8-d727-4f58-84e7-c3cd5ffbd12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_path = r\"/storage/users/assafzar/Muscle_Differentiation_AvinoamLab/\"\n",
    "data_csv_path = storage_path + r\"data/mastodon/%s%s all detections.csv\"\n",
    "intensity_model_path = storage_path + r\"15-12-2022-actin_intensity local dens-False, s%s, s%s train [130, 160] diff window win size 16/track len 30, impute_func-ImputeAllData_impute_zeroes reg MeanOpticalFlowReg_/\"\n",
    "motility_model_path = storage_path + r\"15-12-2022-motility local dens-False, s%s, s%s train [130, 160] diff window/track len 30, impute_func-ImputeAllData_impute_zeroes reg MeanOpticalFlowReg_/\"\n",
    "FEATURES_DIR_PATH = f\"data/mastodon/features/\"\n",
    "transformed_data_path = '/storage/users/assafzar/Muscle_Differentiation_AvinoamLab/data/mastodon/ts_transformed/%s/ImputeAllData_impute_zeroes/S%s/merged_chunks_reg=MeanOpticalFlowReg_,local_den=False,win size=16.pkl'\n",
    "\n",
    "\n",
    "REG_METHOD = \"MeanOpticalFlowReg_\"\n",
    "IMPUTE_FUNC = \"impute_zeroes\"\n",
    "IMPUTE_METHOD = \"ImputeAllData\"\n",
    "WIN_SIZE=16\n",
    "diff_window=[130, 160] \n",
    "con_window=[[0, 30], [40, 70], [90, 120], [130, 160], [180, 210], [220, 250]]\n",
    "transformed_data_path=storage_path + f\"data/mastodon/ts_transformed/%s/{IMPUTE_METHOD}_{IMPUTE_FUNC}/S%s/merged_chunks_reg={REG_METHOD},local_den=False,win size={WIN_SIZE}.pkl\"\n",
    "SEGMENT_LEN = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ce82472-ad8d-4b8b-bc23-ac7997f33ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_redundant_columns(df):\n",
    "    remove_cols = []\n",
    "    cols_to_remove = [\"target\"]\n",
    "    for col_to_remove in cols_to_remove:\n",
    "        for col_name in df.columns:\n",
    "            if col_name.startswith(col_to_remove):\n",
    "                remove_cols.append(col_name)\n",
    "    df = df.drop(columns=remove_cols)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f8d8e61-1f63-4703-b1c9-c7b491efe56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast_df(data_copy, fillna=True):\n",
    "    \"\"\"\n",
    "    Downcasts the data types of a DataFrame to reduce memory usage.\n",
    "    :param data_copy: (pd.DataFrame) The DataFrame to be downcasted.\n",
    "    :param fillna: (bool, optional) Whether to fill NaN values with zero. Default is True.\n",
    "    :return: (pd.DataFrame) The downcasted DataFrame.\n",
    "    \"\"\"\n",
    "    data_copy = data_copy.copy()\n",
    "    if fillna:\n",
    "        data_copy = data_copy.fillna(0)\n",
    "    data_copy = data_copy.dropna(axis=1)\n",
    "    cols = list(data_copy.drop(columns=\"Spot track ID\").columns) if \"spot track ID\" in data_copy.columns else list(\n",
    "        data_copy.columns)\n",
    "    for col in cols:\n",
    "        try:\n",
    "            if data_copy[col].sum().is_integer():\n",
    "                data_copy[col] = pd.to_numeric(data_copy[col], downcast='integer')\n",
    "            else:\n",
    "                data_copy[col] = pd.to_numeric(data_copy[col], downcast='float')\n",
    "\n",
    "            if np.isinf(data_copy[col]).sum() > 0:\n",
    "                data_copy[col] = data_copy[col]\n",
    "        except:\n",
    "            continue\n",
    "    return data_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7758116f-4374-4431-bcdf-0cc24c5927cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tsfresh_csv(transfromed_pkl_path, modality, vid_num):\n",
    "    print(f\"read data from video number {vid_num}\")\n",
    "    df = pickle.load(open(transfromed_pkl_path % (modality, vid_num), 'rb'))\n",
    "    df = downcast_df(df, fillna=False)\n",
    "    df = clean_redundant_columns(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39114126-4f5d-48a2-be7e-b853c89ba876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_to_run(transformed_data_path, modality, con_train_num=None, con_test_num=None, diff_train_num=None,\n",
    "               diff_test_num=None):\n",
    "    diff_df_train, con_df_train, con_df_test, diff_df_test = None, None, None, None\n",
    "\n",
    "    if diff_train_num:\n",
    "        diff_df_train = load_tsfresh_csv(transformed_data_path, modality, diff_train_num)\n",
    "        print(f\"diff train len: {diff_df_train.shape}\", flush=True)\n",
    "\n",
    "    if con_train_num:\n",
    "        con_df_train = load_tsfresh_csv(transformed_data_path, modality, con_train_num)\n",
    "        print(f\"con_df_train len: {con_df_train.shape}\", flush=True)\n",
    "\n",
    "    if con_test_num:\n",
    "        con_df_test = load_tsfresh_csv(transformed_data_path, modality, con_test_num)\n",
    "\n",
    "    if diff_test_num:\n",
    "        diff_df_test = load_tsfresh_csv(transformed_data_path, modality, diff_test_num)\n",
    "\n",
    "    return diff_df_train, con_df_train, con_df_test, diff_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff61e6f5-f980-4ab4-9c18-23aab73ed215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(modality, path, con_train_n, diff_train_n, con_test_n, diff_test_n):\n",
    "    diff_df_train, con_df_train, con_df_test, diff_df_test = get_to_run(transformed_data_path=path,\n",
    "                                                                            modality=modality,\n",
    "                                                                            con_train_num=con_train_n,\n",
    "                                                                            diff_train_num=diff_train_n,\n",
    "                                                                            con_test_num=con_test_n,\n",
    "                                                                            diff_test_num=diff_test_n)\n",
    "    if (con_train_n is not None) and (diff_train_n is not None):\n",
    "        diff_df = diff_df_train\n",
    "        con_df = con_df_train\n",
    "\n",
    "    elif (con_test_n is not None) and (diff_test_n is not None):\n",
    "        diff_df = diff_df_test\n",
    "        con_df = con_df_test\n",
    "    print(\"ended loading\", flush=True)\n",
    "    return diff_df, con_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6fd847a-6ef2-42c2-afed-3f17c2a26a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_dfs(diff_df, con_df, diff_t_window=None, con_t_windows=None):\n",
    "    def set_indexes(df, target, max_val):\n",
    "        df[\"Spot track ID\"] = df[\"Spot track ID\"] + max_val\n",
    "        max_val = df[\"Spot track ID\"].max() + 1\n",
    "        df['target'] = np.array([target for i in range(len(df))])\n",
    "        return df, max_val\n",
    "\n",
    "    max_val = 0\n",
    "    diff_start, diff_end = diff_t_window\n",
    "    window_size = diff_end - diff_start\n",
    "\n",
    "    # Erk video\n",
    "    # Cut the needed time window\n",
    "    new_diff_df = pd.DataFrame()\n",
    "    diff_df = diff_df[diff_df[\"Spot frame\"] == diff_end]\n",
    "    print(\"size of diff_df: \", diff_df.shape)\n",
    "\n",
    "    for label, label_df in diff_df.groupby('Spot track ID'):\n",
    "        # new_diff_df = new_diff_df.append(label_df)\n",
    "        new_diff_df = pd.concat([new_diff_df, label_df], ignore_index=True)\n",
    "\n",
    "    # control video\n",
    "    # Cut the needed time window\n",
    "    control_df = pd.DataFrame()\n",
    "    new_label = max(con_df['Spot track ID'].unique()) + 1\n",
    "    for start, end in con_t_windows:\n",
    "        tmp_df = con_df[con_df[\"Spot frame\"] == end]\n",
    "        for label, label_df in tmp_df.groupby('Spot track ID'):\n",
    "            new_label += 1\n",
    "            label_df[\"Spot track ID\"] = new_label\n",
    "            # control_df = control_df.append(label_df)\n",
    "            control_df = pd.concat([control_df, label_df], ignore_index=True)\n",
    "    con_df = control_df.copy()\n",
    "    print(\"size of con_df: \", con_df.shape)\n",
    "\n",
    "    new_diff_df, max_val = set_indexes(new_diff_df, target=True, max_val=max_val)\n",
    "    con_df, _ = set_indexes(con_df, target=False, max_val=max_val)\n",
    "    total_df = pd.concat([new_diff_df, con_df], ignore_index=True)\n",
    "    return total_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1d68b89-1a78-49a0-b211-bb7198598948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(diff_df, con_df, diff_t_window, con_t_windows):\n",
    "    print(\"\\n preparing data\", flush=True)\n",
    "    print(\"\\nconcatenating control data & ERKi data\")\n",
    "    df = concat_dfs(diff_df, con_df, diff_t_window, con_t_windows)\n",
    "    del diff_df\n",
    "    del con_df\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    print(\"\\nshape after concat_dfs\", df.shape)\n",
    "\n",
    "    df = df.replace([np.inf], np.nan)\n",
    "    df = df.dropna(axis=1)\n",
    "    print(\"\\nshape after dropna\", df.shape)\n",
    "\n",
    "    df.index = df['Spot track ID']\n",
    "    y = pd.Series(df['target'])\n",
    "    y.index = df['Spot track ID']\n",
    "    df = df.drop([\"target\", \"Spot frame\", \"Spot track ID\"], axis=1)\n",
    "    return df, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "742a9a13-9ec0-4af0-909d-5255da11dec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(\n",
    "    X,\n",
    "    y,\n",
    "    test_for_binary_target_binary_feature=defaults.TEST_FOR_BINARY_TARGET_BINARY_FEATURE,\n",
    "    test_for_binary_target_real_feature=defaults.TEST_FOR_BINARY_TARGET_REAL_FEATURE,\n",
    "    test_for_real_target_binary_feature=defaults.TEST_FOR_REAL_TARGET_BINARY_FEATURE,\n",
    "    test_for_real_target_real_feature=defaults.TEST_FOR_REAL_TARGET_REAL_FEATURE,\n",
    "    fdr_level=defaults.FDR_LEVEL,\n",
    "    hypotheses_independent=defaults.HYPOTHESES_INDEPENDENT,\n",
    "    n_jobs=defaults.N_PROCESSES,\n",
    "    show_warnings=defaults.SHOW_WARNINGS,\n",
    "    chunksize=defaults.CHUNKSIZE,\n",
    "    ml_task=\"auto\",\n",
    "    multiclass=False,\n",
    "    n_significant=1,\n",
    "):\n",
    "    assert isinstance(X, pd.DataFrame), \"Please pass features in X as pandas.DataFrame.\"\n",
    "    check_for_nans_in_columns(X)\n",
    "    assert isinstance(y, (pd.Series, np.ndarray)), (\n",
    "        \"The type of target vector y must be one of: \" \"pandas.Series, numpy.ndarray\"\n",
    "    )\n",
    "    assert len(y) > 1, \"y must contain at least two samples.\"\n",
    "    assert len(X) == len(y), \"X and y must contain the same number of samples.\"\n",
    "    assert (\n",
    "        len(set(y)) > 1\n",
    "    ), \"Feature selection is only possible if more than 1 label/class is provided\"\n",
    "\n",
    "    if isinstance(y, pd.Series) and set(X.index) != set(y.index):\n",
    "        raise ValueError(\"Index of X and y must be identical if provided\")\n",
    "\n",
    "    if isinstance(y, np.ndarray):\n",
    "        y = pd.Series(y, index=X.index)\n",
    "\n",
    "    relevance_table = calculate_relevance_table(\n",
    "        X,\n",
    "        y,\n",
    "        ml_task=ml_task,\n",
    "        multiclass=multiclass,\n",
    "        n_significant=n_significant,\n",
    "        n_jobs=n_jobs,\n",
    "        show_warnings=show_warnings,\n",
    "        chunksize=chunksize,\n",
    "        test_for_binary_target_real_feature=test_for_binary_target_real_feature,\n",
    "        fdr_level=fdr_level,\n",
    "        hypotheses_independent=hypotheses_independent,\n",
    "    )\n",
    "\n",
    "    relevant_features = relevance_table[relevance_table.relevant].feature\n",
    "\n",
    "    return X.loc[:, relevant_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "047f82a7-01bb-44a5-81ca-c94d1329f345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(dir_path, clf=None, X_train=None, X_test=None, y_train=None, y_test=None):\n",
    "    \"\"\"\n",
    "    Saves a classifier, train & test data of a given model in a directory.\n",
    "    :param dir_path: (str) Directory path where the files will be saved\n",
    "    :param clf: (bool, optional) Whether to save the classifier. Default is True.\n",
    "    :param X_train: (bool, optional) Whether to save the training input data. Default is True.\n",
    "    :param X_test: (bool, optional) Whether to save the testing input data. Default is True.\n",
    "    :param y_train: (bool, optional) Whether to save the training target data. Default is True.\n",
    "    :param y_test: (bool, optional) Whether to save the testing target data. Default is True.\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    if X_train is not None:\n",
    "        X_train.to_csv(dir_path + \"/\" + \"X_train\")\n",
    "    if X_test is not None:\n",
    "        X_test.to_csv(dir_path + \"/\" + \"X_test\")\n",
    "    if y_test is not None:\n",
    "        y_test.to_csv(dir_path + \"/\" + \"y_test\")\n",
    "    if y_train is not None:\n",
    "        y_train.to_csv(dir_path + \"/\" + \"y_train\")\n",
    "    if clf is not None:\n",
    "        joblib.dump(clf, dir_path + \"/\" + \"clf.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0f4c855-eee3-483c-9efc-f07918a2f619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(clf, X_test, y_test):\n",
    "    pred = clf.predict(X_test)\n",
    "    # report = classification_report(y_test, pred)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, pred, pos_label=1)\n",
    "    auc_score = metrics.auc(fpr, tpr)\n",
    "    print(auc_score)\n",
    "    return auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5f39224-90e4-42d3-8e62-729f21da9250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clf(dir_path, clf, X_test, y_test, y_train, diff_window, con_window):\n",
    "    auc_score = evaluate(clf, X_test, y_test)\n",
    "    txt_file = open(dir_path + '/info.txt', 'a')\n",
    "    txt_file.write(\n",
    "                   f\"\\n auc score: {auc_score}\"\n",
    "                   f\"\\n train samples:{Counter(y_train)}\"\n",
    "                   f\"\\n {diff_window} ERK, {con_window} con frames\"\n",
    "                   f\"\\n n features= {X_test.shape}\")\n",
    "\n",
    "    txt_file.close()\n",
    "\n",
    "    return auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3780b251-726b-453f-9929-7c3cfb99edb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_state_prediction_model_light_with_seed(save_dir_path, con_window, diff_window, modality, diff_df_test, con_df_test, diff_df_train, con_df_train, seed, to_save=True):\n",
    "    \"\"\"\n",
    "    duild a classifier with seed number of random forest.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"loaded data, now start prep data\", flush=True)\n",
    "    X_train, y_train = prep_data(diff_df=diff_df_train, con_df=con_df_train, diff_t_window=diff_window,\n",
    "                                 con_t_windows=con_window)\n",
    "    X_train = downcast_df(X_train)\n",
    "\n",
    "    del diff_df_train\n",
    "    del con_df_train\n",
    "    print(\"deleted diff_df_train, con_df_train\", flush=True)\n",
    "\n",
    "    X_train = select_features(X_train, y_train, n_jobs=10)  # , chunksize=10\n",
    "    print(\"Done feature selection\", flush=True)\n",
    "\n",
    "    clf = train_model_with_seed(X_train, y_train, modality, seed)\n",
    "    if to_save:\n",
    "        save_data(save_dir_path, X_train=X_train)\n",
    "\n",
    "    X_test, y_test = prep_data(diff_df=diff_df_test, con_df=con_df_test, diff_t_window=diff_window,\n",
    "                               con_t_windows=con_window)\n",
    "    X_test = X_test[list(clf.feature_names_in_)]\n",
    "    evaluate_clf(save_dir_path, clf, X_test, y_test, y_train, diff_window, con_window)\n",
    "    \n",
    "    if to_save:\n",
    "        save_data(save_dir_path, y_train=y_train, X_test=X_test, y_test=y_test, clf=clf)\n",
    "    save_data(save_dir_path,clf=clf)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca29284a-6de3-4bfe-87fc-4dfe390b2f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_state_trajectory(transformed_tracks_df, clf, n_frames=260):\n",
    "    df_score = pd.DataFrame(columns=[i for i in range(n_frames)])\n",
    "    for track_id, track in transformed_tracks_df.groupby(\"Spot track ID\"):\n",
    "        spot_frames = list(track.sort_values(\"Spot frame\")[\"Spot frame\"])\n",
    "        diff_score = {\"Spot track ID\": track_id}\n",
    "        try:\n",
    "            for t in spot_frames:\n",
    "                probs = clf.predict_proba(track[track[\"Spot frame\"] == t].drop([\"Spot track ID\", \"Spot frame\"], axis=1))\n",
    "                diff_score[t] = pd.to_numeric(probs[0][1], downcast='float')\n",
    "\n",
    "            diff_score_df = pd.DataFrame(diff_score, index=[0])\n",
    "            df_score = pd.concat([df_score, diff_score_df], ignore_index=True, sort=False)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(track[track[\"Spot frame\"] == t].drop([\"Spot track ID\", \"Spot frame\"], axis=1).size)\n",
    "    print(df_score.shape)\n",
    "    return df_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12fc0a1c-e9bb-4004-a77d-6d233a90e976",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model_with_seed(X_train, y_train, modality, seed):\n",
    "\n",
    "    params_dict = {\n",
    "        \"motility\": {'max_depth': 12, 'min_samples_leaf': 1, 'n_estimators': 100, 'random_state': seed},\n",
    "        \"actin_intensity\": {'max_depth': 20, 'min_samples_leaf': 1, 'n_estimators': 200, 'random_state': seed}\n",
    "    }\n",
    "    params = params_dict.get(modality) if params_dict.get(modality) is not None else {}\n",
    "\n",
    "    clf = RandomForestClassifier(**params, )\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c2380fe-e28e-47e9-8697-998734a1fa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model_without_seed(X_train, y_train, modality):\n",
    "\n",
    "    params_dict = {\"motility\": {'max_depth': 12, 'min_samples_leaf': 1, 'n_estimators': 100},\n",
    "                   \"actin_intensity\": {'max_depth': 20, 'min_samples_leaf': 1, 'n_estimators': 200}}\n",
    "    params = params_dict.get(modality) if params_dict.get(modality) is not None else {}\n",
    "\n",
    "    clf = RandomForestClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26d92fc-b442-4c11-a6d2-dbf9cd228e1d",
   "metadata": {},
   "source": [
    "## build random forest models ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "556037f7-ae1a-4806-9ada-c11fbdad4a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "modality='actin_intensity'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ff715c-0704-4367-a4c8-d0db3e9327d3",
   "metadata": {},
   "source": [
    "### get video data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e3322df-0936-4b56-88c1-7be17abb3f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read data from video number 2\n",
      "read data from video number 3\n",
      "ended loading\n",
      "read data from video number 5\n",
      "diff train len: (47703, 3158)\n",
      "read data from video number 1\n",
      "con_df_train len: (16297, 3158)\n",
      "ended loading\n"
     ]
    }
   ],
   "source": [
    "diff_df_te, con_df_te = get_data(modality, transformed_data_path, None, None, 2, 3)\n",
    "diff_df_tra, con_df_tra = get_data(modality, transformed_data_path, 1, 5, None, None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "480604d2-69be-4b8a-96b5-829d01a70713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " train: con_n-1,dif_n-5; test: con_n-2,dif_n-3\n",
      "model_name: actin_intensity\n",
      "loaded data, now start prep data\n",
      "\n",
      " preparing data\n",
      "\n",
      "concatenating control data & ERKi data\n",
      "size of diff_df:  (268, 3158)\n",
      "size of con_df:  (459, 3158)\n",
      "\n",
      "shape after concat_dfs (727, 3159)\n",
      "\n",
      "shape after dropna (727, 3159)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_115061/2825200806.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['target'] = np.array([target for i in range(len(df))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted diff_df_train, con_df_train\n",
      "Done feature selection\n",
      "\n",
      " preparing data\n",
      "\n",
      "concatenating control data & ERKi data\n",
      "size of diff_df:  (577, 3158)\n",
      "size of con_df:  (180, 3158)\n",
      "\n",
      "shape after concat_dfs (757, 3159)\n",
      "\n",
      "shape after dropna (757, 3159)\n",
      "0.8001684960523782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_115061/2825200806.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['target'] = np.array([target for i in range(len(df))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calc avg prob\n",
      "(5, 261)\n"
     ]
    }
   ],
   "source": [
    "today = datetime.datetime.now().strftime('%d-%m-%Y')\n",
    "id_list = [16771, 27879, 16991, 16003, 8598]\n",
    "\n",
    "for con_train_n, diff_train_n, con_test_n, diff_test_n in [(1, 5, 2, 3)]:\n",
    "    print(f\"\\n train: con_n-{con_train_n},dif_n-{diff_train_n}; test: con_n-{con_test_n},dif_n-{diff_test_n}\")    \n",
    "    print(f\"model_name: {modality}\")\n",
    "\n",
    "    flag_save_data = True\n",
    "    \n",
    "    for i in range(0,1):  \n",
    "        if i != 0:\n",
    "            flag_save_data = False \n",
    "        dir_path = f\"{storage_path}/confidence_interval/{today}-{modality} local dens-False, s{con_train_n}, s{diff_train_n} train\" \\\n",
    "               + (f\" win size {WIN_SIZE}\" if modality != \"motility\" else \"\")\n",
    "\n",
    "        second_dir = f\"track len {SEGMENT_LEN}, impute_func-{IMPUTE_METHOD}_{IMPUTE_FUNC} reg {REG_METHOD}\"\n",
    "\n",
    "        seed = i + 1  # Seed value starts from 1\n",
    "        save_dir_path = dir_path + \"/\" + second_dir + \"/\" + f\"model_num-{i+1}, seed_num-{seed}\"\n",
    "\n",
    "\n",
    "        sec_dir=f'{i}'\n",
    "        os.makedirs((save_dir_path), exist_ok=True)\n",
    "\n",
    "        clf =build_state_prediction_model_light_with_seed(save_dir_path=save_dir_path,\n",
    "                                             con_window=con_window,\n",
    "                                             diff_window=diff_window, modality=modality, diff_df_test=diff_df_te,\n",
    "                                             con_df_test=con_df_te, diff_df_train=diff_df_tra, con_df_train=con_df_tra, seed=seed, to_save=flag_save_data)\n",
    "        cols = list(clf.feature_names_in_)\n",
    "        cols.extend([\"Spot track ID\", \"Spot frame\"])\n",
    "\n",
    "        print(\"calc avg prob\")\n",
    "\n",
    "        df = diff_df_te[cols].dropna(axis=1)\n",
    "        filtered_df = df[df['Spot track ID'].isin(id_list)]\n",
    "        df_score_dif = calc_state_trajectory(filtered_df, clf, n_frames=260)\n",
    "\n",
    "        pickle.dump(df_score_dif, open(save_dir_path + \"/\" + f\"df_score_vid_num_S{diff_test_n}.pkl\", 'wb'))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdf5464-9c26-4ec5-b751-23bb48f8c9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/storage/users/assafzar/Muscle_Differentiation_AvinoamLab/confidence_interval/07-06-2023-actin_intensity local dens-False, s2, s3 train win size 16/track len 30, impute_func-ImputeAllData_impute_zeroes reg MeanOpticalFlowReg_/0df_score_vid_num_S5.pkl', 'rb') as f:\n",
    "    x = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
